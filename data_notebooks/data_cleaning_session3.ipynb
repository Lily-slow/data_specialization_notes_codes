{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 3 - Data cleaning\n",
    "\n",
    "Today we're going to look at how to clean data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   color      director_name  num_critic_for_reviews  duration   \n0  Color      James Cameron                   723.0     178.0  \\\n1  Color     Gore Verbinski                   302.0     169.0   \n2  Color         Sam Mendes                   602.0     148.0   \n3  Color  Christopher Nolan                   813.0     164.0   \n4    NaN        Doug Walker                     NaN       NaN   \n\n   director_facebook_likes  actor_3_facebook_likes      actor_2_name   \n0                      0.0                   855.0  Joel David Moore  \\\n1                    563.0                  1000.0     Orlando Bloom   \n2                      0.0                   161.0      Rory Kinnear   \n3                  22000.0                 23000.0    Christian Bale   \n4                    131.0                     NaN        Rob Walker   \n\n   actor_1_facebook_likes        gross                           genres  ...   \n0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi  ...  \\\n1                 40000.0  309404152.0         Action|Adventure|Fantasy  ...   \n2                 11000.0  200074175.0        Action|Adventure|Thriller  ...   \n3                 27000.0  448130642.0                  Action|Thriller  ...   \n4                   131.0          NaN                      Documentary  ...   \n\n  num_user_for_reviews language  country  content_rating       budget   \n0               3054.0  English      USA           PG-13  237000000.0  \\\n1               1238.0  English      USA           PG-13  300000000.0   \n2                994.0  English       UK           PG-13  245000000.0   \n3               2701.0  English      USA           PG-13  250000000.0   \n4                  NaN      NaN      NaN             NaN          NaN   \n\n   title_year actor_2_facebook_likes imdb_score  aspect_ratio   \n0      2009.0                  936.0        7.9          1.78  \\\n1      2007.0                 5000.0        7.1          2.35   \n2      2015.0                  393.0        6.8          2.35   \n3      2012.0                23000.0        8.5          2.35   \n4         NaN                   12.0        7.1           NaN   \n\n  movie_facebook_likes  \n0                33000  \n1                    0  \n2                85000  \n3               164000  \n4                    0  \n\n[5 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>color</th>\n      <th>director_name</th>\n      <th>num_critic_for_reviews</th>\n      <th>duration</th>\n      <th>director_facebook_likes</th>\n      <th>actor_3_facebook_likes</th>\n      <th>actor_2_name</th>\n      <th>actor_1_facebook_likes</th>\n      <th>gross</th>\n      <th>genres</th>\n      <th>...</th>\n      <th>num_user_for_reviews</th>\n      <th>language</th>\n      <th>country</th>\n      <th>content_rating</th>\n      <th>budget</th>\n      <th>title_year</th>\n      <th>actor_2_facebook_likes</th>\n      <th>imdb_score</th>\n      <th>aspect_ratio</th>\n      <th>movie_facebook_likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Color</td>\n      <td>James Cameron</td>\n      <td>723.0</td>\n      <td>178.0</td>\n      <td>0.0</td>\n      <td>855.0</td>\n      <td>Joel David Moore</td>\n      <td>1000.0</td>\n      <td>760505847.0</td>\n      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n      <td>...</td>\n      <td>3054.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>PG-13</td>\n      <td>237000000.0</td>\n      <td>2009.0</td>\n      <td>936.0</td>\n      <td>7.9</td>\n      <td>1.78</td>\n      <td>33000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Color</td>\n      <td>Gore Verbinski</td>\n      <td>302.0</td>\n      <td>169.0</td>\n      <td>563.0</td>\n      <td>1000.0</td>\n      <td>Orlando Bloom</td>\n      <td>40000.0</td>\n      <td>309404152.0</td>\n      <td>Action|Adventure|Fantasy</td>\n      <td>...</td>\n      <td>1238.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>PG-13</td>\n      <td>300000000.0</td>\n      <td>2007.0</td>\n      <td>5000.0</td>\n      <td>7.1</td>\n      <td>2.35</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Color</td>\n      <td>Sam Mendes</td>\n      <td>602.0</td>\n      <td>148.0</td>\n      <td>0.0</td>\n      <td>161.0</td>\n      <td>Rory Kinnear</td>\n      <td>11000.0</td>\n      <td>200074175.0</td>\n      <td>Action|Adventure|Thriller</td>\n      <td>...</td>\n      <td>994.0</td>\n      <td>English</td>\n      <td>UK</td>\n      <td>PG-13</td>\n      <td>245000000.0</td>\n      <td>2015.0</td>\n      <td>393.0</td>\n      <td>6.8</td>\n      <td>2.35</td>\n      <td>85000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Color</td>\n      <td>Christopher Nolan</td>\n      <td>813.0</td>\n      <td>164.0</td>\n      <td>22000.0</td>\n      <td>23000.0</td>\n      <td>Christian Bale</td>\n      <td>27000.0</td>\n      <td>448130642.0</td>\n      <td>Action|Thriller</td>\n      <td>...</td>\n      <td>2701.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>PG-13</td>\n      <td>250000000.0</td>\n      <td>2012.0</td>\n      <td>23000.0</td>\n      <td>8.5</td>\n      <td>2.35</td>\n      <td>164000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Doug Walker</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>131.0</td>\n      <td>NaN</td>\n      <td>Rob Walker</td>\n      <td>131.0</td>\n      <td>NaN</td>\n      <td>Documentary</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>7.1</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First lets read in some movie metadata that we know needs cleaning. \n",
    "# This dataset is from Kaggle (https://www.kaggle.com/datasets/carolzhangdc/imdb-5000-movie-dataset)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/movie_metadata_unclean.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's examine our data\n",
    "\n",
    "\n",
    "1. When we look at the dataset  we can start to note down the problems, and then we’ll come up with solutions to fix those problems.\n",
    "\n",
    "2. Pandas has some selection methods which we can use to slice and dice the dataset based on your queries.\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "- Look at the some basic stats for the ‘imdb_score’ column: `data.imdb_score.describe()`\n",
    "- Select a column: `data[‘movie_title’]`\n",
    "- Select the first 10 rows of a column: `data[‘duration’][:10]`\n",
    "- Select multiple columns: `data[[‘budget’,’gross’]]`\n",
    "- Select all movies over two hours long: `data[data[‘duration’] > 120]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    5043.000000\nmean        6.442138\nstd         1.125116\nmin         1.600000\n25%         5.800000\n50%         6.600000\n75%         7.200000\nmax         9.500000\nName: imdb_score, dtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.imdb_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0                                                 Avatar \n1               Pirates of the Caribbean: At World's End \n2                                                Spectre \n3                                  The Dark Knight Rises \n4       Star Wars: Episode VII - The Force Awakens    ...\n                              ...                        \n5038                             Signed Sealed Delivered \n5039                           The Following             \n5040                                A Plague So Pleasant \n5041                                    Shanghai Calling \n5042                                   My Date with Drew \nName: movie_title, Length: 5043, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['movie_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                         movie_title  duration\n0                                            Avatar      178.0\n1          Pirates of the Caribbean: At World's End      169.0\n2                                           Spectre      148.0\n3                             The Dark Knight Rises      164.0\n4  Star Wars: Episode VII - The Force Awakens    ...       NaN\n5                                       John Carter      132.0\n6                                      Spider-Man 3      156.0\n7                                           Tangled      100.0\n8                           Avengers: Age of Ultron      141.0\n9            Harry Potter and the Half-Blood Prince      153.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_title</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Avatar</td>\n      <td>178.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pirates of the Caribbean: At World's End</td>\n      <td>169.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Spectre</td>\n      <td>148.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Dark Knight Rises</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Star Wars: Episode VII - The Force Awakens    ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>John Carter</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Spider-Man 3</td>\n      <td>156.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Tangled</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Avengers: Age of Ultron</td>\n      <td>141.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Harry Potter and the Half-Blood Prince</td>\n      <td>153.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['movie_title','duration']][:10]\n",
    "data['duration'].head(10)\n",
    "# same purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           budget        gross\n0     237000000.0  760505847.0\n1     300000000.0  309404152.0\n2     245000000.0  200074175.0\n3     250000000.0  448130642.0\n4             NaN          NaN\n...           ...          ...\n5038          NaN          NaN\n5039          NaN          NaN\n5040       1400.0          NaN\n5041          NaN      10443.0\n5042       1100.0      85222.0\n\n[5043 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>gross</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>237000000.0</td>\n      <td>760505847.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>300000000.0</td>\n      <td>309404152.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>245000000.0</td>\n      <td>200074175.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>250000000.0</td>\n      <td>448130642.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5038</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5039</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5040</th>\n      <td>1400.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5041</th>\n      <td>NaN</td>\n      <td>10443.0</td>\n    </tr>\n    <tr>\n      <th>5042</th>\n      <td>1100.0</td>\n      <td>85222.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5043 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['budget','gross']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 color        director_name  num_critic_for_reviews  duration   \n0                Color        James Cameron                   723.0     178.0  \\\n1                Color       Gore Verbinski                   302.0     169.0   \n2                Color           Sam Mendes                   602.0     148.0   \n3                Color    Christopher Nolan                   813.0     164.0   \n5                Color       Andrew Stanton                   462.0     132.0   \n...                ...                  ...                     ...       ...   \n4842             Color         Julie Taymor                   156.0     133.0   \n4885   Black and White           King Vidor                    48.0     151.0   \n4894             Color    Richard Fleischer                    69.0     127.0   \n4912   Black and White  Carl Theodor Dreyer                    54.0     126.0   \n5020               NaN      Brandon Landers                     NaN     143.0   \n\n      director_facebook_likes  actor_3_facebook_likes      actor_2_name   \n0                         0.0                   855.0  Joel David Moore  \\\n1                       563.0                  1000.0     Orlando Bloom   \n2                         0.0                   161.0      Rory Kinnear   \n3                     22000.0                 23000.0    Christian Bale   \n5                       475.0                   530.0   Samantha Morton   \n...                       ...                     ...               ...   \n4842                    278.0                   107.0       T.V. Carpio   \n4885                     54.0                     6.0      Renée Adorée   \n4894                    130.0                    51.0   Robert J. Wilke   \n4912                    147.0                     0.0  Sylvia Eckhausen   \n5020                      8.0                     8.0   Alana Kaniewski   \n\n      actor_1_facebook_likes        gross   \n0                     1000.0  760505847.0  \\\n1                    40000.0  309404152.0   \n2                    11000.0  200074175.0   \n3                    27000.0  448130642.0   \n5                      640.0   73058679.0   \n...                      ...          ...   \n4842                  5000.0   24343673.0   \n4885                    81.0          NaN   \n4894                   618.0          NaN   \n4912                     0.0          NaN   \n5020                   720.0          NaN   \n\n                                     genres  ... num_user_for_reviews   \n0           Action|Adventure|Fantasy|Sci-Fi  ...               3054.0  \\\n1                  Action|Adventure|Fantasy  ...               1238.0   \n2                 Action|Adventure|Thriller  ...                994.0   \n3                           Action|Thriller  ...               2701.0   \n5                   Action|Adventure|Sci-Fi  ...                738.0   \n...                                     ...  ...                  ...   \n4842          Drama|Fantasy|Musical|Romance  ...                524.0   \n4885                      Drama|Romance|War  ...                 45.0   \n4894  Adventure|Drama|Family|Fantasy|Sci-Fi  ...                108.0   \n4912                          Drama|Fantasy  ...                 49.0   \n5020                  Drama|Horror|Thriller  ...                  8.0   \n\n     language  country  content_rating       budget  title_year   \n0     English      USA           PG-13  237000000.0      2009.0  \\\n1     English      USA           PG-13  300000000.0      2007.0   \n2     English       UK           PG-13  245000000.0      2015.0   \n3     English      USA           PG-13  250000000.0      2012.0   \n5     English      USA           PG-13  263700000.0      2012.0   \n...       ...      ...             ...          ...         ...   \n4842  English      USA           PG-13   45000000.0      2007.0   \n4885      NaN      USA       Not Rated     245000.0      1925.0   \n4894  English      USA        Approved    5000000.0      1954.0   \n4912   Danish  Denmark       Not Rated          NaN      1955.0   \n5020  English      USA             NaN      17350.0      2011.0   \n\n     actor_2_facebook_likes imdb_score  aspect_ratio movie_facebook_likes  \n0                     936.0        7.9          1.78                33000  \n1                    5000.0        7.1          2.35                    0  \n2                     393.0        6.8          2.35                85000  \n3                   23000.0        8.5          2.35               164000  \n5                     632.0        6.6          2.35                24000  \n...                     ...        ...           ...                  ...  \n4842                  117.0        7.4          2.35                14000  \n4885                   12.0        8.3          1.33                  226  \n4894                   53.0        7.2          1.37                    0  \n4912                    0.0        8.1          1.37                  863  \n5020                   19.0        3.0           NaN                   33  \n\n[1067 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>color</th>\n      <th>director_name</th>\n      <th>num_critic_for_reviews</th>\n      <th>duration</th>\n      <th>director_facebook_likes</th>\n      <th>actor_3_facebook_likes</th>\n      <th>actor_2_name</th>\n      <th>actor_1_facebook_likes</th>\n      <th>gross</th>\n      <th>genres</th>\n      <th>...</th>\n      <th>num_user_for_reviews</th>\n      <th>language</th>\n      <th>country</th>\n      <th>content_rating</th>\n      <th>budget</th>\n      <th>title_year</th>\n      <th>actor_2_facebook_likes</th>\n      <th>imdb_score</th>\n      <th>aspect_ratio</th>\n      <th>movie_facebook_likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Color</td>\n      <td>James Cameron</td>\n      <td>723.0</td>\n      <td>178.0</td>\n      <td>0.0</td>\n      <td>855.0</td>\n      <td>Joel David Moore</td>\n      <td>1000.0</td>\n      <td>760505847.0</td>\n      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n      <td>...</td>\n      <td>3054.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>PG-13</td>\n      <td>237000000.0</td>\n      <td>2009.0</td>\n      <td>936.0</td>\n      <td>7.9</td>\n      <td>1.78</td>\n      <td>33000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Color</td>\n      <td>Gore Verbinski</td>\n      <td>302.0</td>\n      <td>169.0</td>\n      <td>563.0</td>\n      <td>1000.0</td>\n      <td>Orlando Bloom</td>\n      <td>40000.0</td>\n      <td>309404152.0</td>\n      <td>Action|Adventure|Fantasy</td>\n      <td>...</td>\n      <td>1238.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>PG-13</td>\n      <td>300000000.0</td>\n      <td>2007.0</td>\n      <td>5000.0</td>\n      <td>7.1</td>\n      <td>2.35</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Color</td>\n      <td>Sam Mendes</td>\n      <td>602.0</td>\n      <td>148.0</td>\n      <td>0.0</td>\n      <td>161.0</td>\n      <td>Rory Kinnear</td>\n      <td>11000.0</td>\n      <td>200074175.0</td>\n      <td>Action|Adventure|Thriller</td>\n      <td>...</td>\n      <td>994.0</td>\n      <td>English</td>\n      <td>UK</td>\n      <td>PG-13</td>\n      <td>245000000.0</td>\n      <td>2015.0</td>\n      <td>393.0</td>\n      <td>6.8</td>\n      <td>2.35</td>\n      <td>85000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Color</td>\n      <td>Christopher Nolan</td>\n      <td>813.0</td>\n      <td>164.0</td>\n      <td>22000.0</td>\n      <td>23000.0</td>\n      <td>Christian Bale</td>\n      <td>27000.0</td>\n      <td>448130642.0</td>\n      <td>Action|Thriller</td>\n      <td>...</td>\n      <td>2701.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>PG-13</td>\n      <td>250000000.0</td>\n      <td>2012.0</td>\n      <td>23000.0</td>\n      <td>8.5</td>\n      <td>2.35</td>\n      <td>164000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Color</td>\n      <td>Andrew Stanton</td>\n      <td>462.0</td>\n      <td>132.0</td>\n      <td>475.0</td>\n      <td>530.0</td>\n      <td>Samantha Morton</td>\n      <td>640.0</td>\n      <td>73058679.0</td>\n      <td>Action|Adventure|Sci-Fi</td>\n      <td>...</td>\n      <td>738.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>PG-13</td>\n      <td>263700000.0</td>\n      <td>2012.0</td>\n      <td>632.0</td>\n      <td>6.6</td>\n      <td>2.35</td>\n      <td>24000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4842</th>\n      <td>Color</td>\n      <td>Julie Taymor</td>\n      <td>156.0</td>\n      <td>133.0</td>\n      <td>278.0</td>\n      <td>107.0</td>\n      <td>T.V. Carpio</td>\n      <td>5000.0</td>\n      <td>24343673.0</td>\n      <td>Drama|Fantasy|Musical|Romance</td>\n      <td>...</td>\n      <td>524.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>PG-13</td>\n      <td>45000000.0</td>\n      <td>2007.0</td>\n      <td>117.0</td>\n      <td>7.4</td>\n      <td>2.35</td>\n      <td>14000</td>\n    </tr>\n    <tr>\n      <th>4885</th>\n      <td>Black and White</td>\n      <td>King Vidor</td>\n      <td>48.0</td>\n      <td>151.0</td>\n      <td>54.0</td>\n      <td>6.0</td>\n      <td>Renée Adorée</td>\n      <td>81.0</td>\n      <td>NaN</td>\n      <td>Drama|Romance|War</td>\n      <td>...</td>\n      <td>45.0</td>\n      <td>NaN</td>\n      <td>USA</td>\n      <td>Not Rated</td>\n      <td>245000.0</td>\n      <td>1925.0</td>\n      <td>12.0</td>\n      <td>8.3</td>\n      <td>1.33</td>\n      <td>226</td>\n    </tr>\n    <tr>\n      <th>4894</th>\n      <td>Color</td>\n      <td>Richard Fleischer</td>\n      <td>69.0</td>\n      <td>127.0</td>\n      <td>130.0</td>\n      <td>51.0</td>\n      <td>Robert J. Wilke</td>\n      <td>618.0</td>\n      <td>NaN</td>\n      <td>Adventure|Drama|Family|Fantasy|Sci-Fi</td>\n      <td>...</td>\n      <td>108.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>Approved</td>\n      <td>5000000.0</td>\n      <td>1954.0</td>\n      <td>53.0</td>\n      <td>7.2</td>\n      <td>1.37</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4912</th>\n      <td>Black and White</td>\n      <td>Carl Theodor Dreyer</td>\n      <td>54.0</td>\n      <td>126.0</td>\n      <td>147.0</td>\n      <td>0.0</td>\n      <td>Sylvia Eckhausen</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>Drama|Fantasy</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>Danish</td>\n      <td>Denmark</td>\n      <td>Not Rated</td>\n      <td>NaN</td>\n      <td>1955.0</td>\n      <td>0.0</td>\n      <td>8.1</td>\n      <td>1.37</td>\n      <td>863</td>\n    </tr>\n    <tr>\n      <th>5020</th>\n      <td>NaN</td>\n      <td>Brandon Landers</td>\n      <td>NaN</td>\n      <td>143.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>Alana Kaniewski</td>\n      <td>720.0</td>\n      <td>NaN</td>\n      <td>Drama|Horror|Thriller</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>English</td>\n      <td>USA</td>\n      <td>NaN</td>\n      <td>17350.0</td>\n      <td>2011.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n<p>1067 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['duration'] > 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing Data\n",
    "\n",
    "One of the most common problems is missing data. This could be because it was never filled out properly, the data wasn’t available, or there was a computing error. \n",
    "\n",
    "> __IMPORTANT: if we leave the blank values in there, it will cause errors in analysis later on, so we need to process the data to deal with missing values__\n",
    "\n",
    "OPTIONS:\n",
    "\n",
    "- Add in a default value for the missing data\n",
    "- Get rid of (delete) the rows that have missing data\n",
    "- Get rid of (delete) the columns that have a high incidence of missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "cast_total_facebook_likes      0\nimdb_score                     0\nmovie_imdb_link                0\nnum_voted_users                0\nmovie_title                    0\ngenres                         0\nmovie_facebook_likes           0\ncountry                        5\nactor_1_facebook_likes         7\nactor_1_name                   7\nactor_2_facebook_likes        13\nactor_2_name                  13\nfacenumber_in_poster          13\nlanguage                      14\nduration                      15\ncolor                         19\nnum_user_for_reviews          21\nactor_3_facebook_likes        23\nactor_3_name                  23\nnum_critic_for_reviews        50\ndirector_facebook_likes      104\ndirector_name                104\ntitle_year                   108\nplot_keywords                153\ncontent_rating               303\naspect_ratio                 329\nbudget                       492\ngross                        884\ndtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how many non-null values in each column\n",
    "len(data) - data.count()\n",
    "(len(data)-data.count()).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Add default values\n",
    "\n",
    "- Let's get rid of all those nasty NaN values. \n",
    "- QUESTION: what to put in its place? This is where we need to jugde the dataset and make an executive decision!\n",
    "\n",
    "For our example, let’s look at the ‘country’ column. It’s straightforward enough, but some of the movies don’t have a country provided so the data shows up as NaN. In this case, we probably don’t want to assume the country, so we can replace it with an __empty string__ or some other default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0       False\n1       False\n2       False\n3       False\n4        True\n        ...  \n5038    False\n5039    False\n5040    False\n5041    False\n5042    False\nName: country, Length: 5043, dtype: bool"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if the country value is null.\n",
    "data.country.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                            movie_title country\n4     Star Wars: Episode VII - The Force Awakens    ...     NaN\n279                            10,000 B.C.                  NaN\n2370                      Gone, Baby, Gone                  NaN\n3397                              Preacher                  NaN\n4021                                       Dawn Patrol      NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_title</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Star Wars: Episode VII - The Force Awakens    ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>10,000 B.C.</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2370</th>\n      <td>Gone, Baby, Gone</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3397</th>\n      <td>Preacher</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4021</th>\n      <td>Dawn Patrol</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see which films don't have a country\n",
    "data[['movie_title', 'country']][data.country.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            movie_title country\n4     Star Wars: Episode VII - The Force Awakens    ...        \n279                            10,000 B.C.                     \n2370                      Gone, Baby, Gone                     ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_title</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Star Wars: Episode VII - The Force Awakens    ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>10,000 B.C.</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2370</th>\n      <td>Gone, Baby, Gone</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This replaces the NaN entries in the ‘country’ column with the empty string, \n",
    "# but we could just as easily tell it to replace with a default name such as “Not known” or \"Other\".\n",
    "\n",
    "data.country = data.country.fillna('')\n",
    "\n",
    "data.loc[[4, 279, 2370]][['movie_title', 'country']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                            movie_title  duration\n4     Star Wars: Episode VII - The Force Awakens    ...       NaN\n199      Harry Potter and the Deathly Hallows: Part II        NaN\n206       Harry Potter and the Deathly Hallows: Part I        NaN\n1510                               Black Water Transit        NaN\n3604                           War & Peace                    NaN\n3815                              Should've Been Romeo        NaN\n3834                                             Barfi        NaN\n4299                            Hum To Mohabbat Karega        NaN\n4392                                          N-Secure        NaN\n4397                               Dil Jo Bhi Kahey...        NaN\n4517                            Wolf Creek                    NaN\n4609                                 Karachi se Lahore        NaN\n4690                                           Destiny        NaN\n4948                                  Romantic Schemer        NaN\n4989                                     The Naked Ape        NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_title</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Star Wars: Episode VII - The Force Awakens    ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Harry Potter and the Deathly Hallows: Part II</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>Harry Potter and the Deathly Hallows: Part I</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1510</th>\n      <td>Black Water Transit</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3604</th>\n      <td>War &amp; Peace</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3815</th>\n      <td>Should've Been Romeo</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3834</th>\n      <td>Barfi</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4299</th>\n      <td>Hum To Mohabbat Karega</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4392</th>\n      <td>N-Secure</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4397</th>\n      <td>Dil Jo Bhi Kahey...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4517</th>\n      <td>Wolf Creek</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4609</th>\n      <td>Karachi se Lahore</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4690</th>\n      <td>Destiny</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4948</th>\n      <td>Romantic Schemer</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4989</th>\n      <td>The Naked Ape</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's look at a numeric column - duration\n",
    "\n",
    "data[['movie_title', 'duration']][data.duration.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                         movie_title    duration\n4  Star Wars: Episode VII - The Force Awakens    ...  107.201074",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_title</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Star Wars: Episode VII - The Force Awakens    ...</td>\n      <td>107.201074</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With numerical data like the \"duration\" of the movie, \n",
    "# a calculation like taking the *mean duration* can help us even the dataset out. \n",
    "\n",
    "# That way we don’t have crazy numbers like 0 or NaN throwing off our analysis.\n",
    "\n",
    "data.duration = data.duration.fillna(data.duration.mean())\n",
    "\n",
    "data.loc[[4]][['movie_title', 'duration']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Remove incomplete rows\n",
    "\n",
    "- Now we want to get rid of any rows that have a missing value. \n",
    "- It’s a pretty aggressive technique, but there may be a use case where that’s exactly what __we want to do.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(5043, 28)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a copy of the data set to play with and count the rows\n",
    "test_data = data.copy()\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3755, 28)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test dropping all rows with any NA values:\n",
    "test_data = data.copy()\n",
    "test_data.dropna(how = 'any', inplace=True)\n",
    "# how = 'any' is default, meaning the row will be dropped if there's at least one missing value.\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(5043, 28)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also drop rows that have ALL NA values (which we don't have any of):\n",
    "test_data = data.copy()\n",
    "# if we only drop the ones with all missing values\n",
    "test_data.dropna(how = 'all', inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(4848, 28)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put a limitation on how many non-null values need to be in a row in order to keep it \n",
    "# (in this example, the data needs to have at least 25 non-null values):\n",
    "test_data = data.copy()\n",
    "# if we allow up to 3 missing values\n",
    "test_data.dropna(thresh=25, inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(4935, 28)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this instance that we don’t want to include any movie \n",
    "# that doesn’t have information on when the movie came out:\n",
    "test_data = data.copy()\n",
    "\n",
    "test_data.dropna(subset=['title_year'], inplace=True)\n",
    "#if we want to drop rows that has null value in either title_year or movie_title\n",
    "test_data.dropna(subset = ['title_year', 'movie_title'], inplace = True)\n",
    "#if we drop rows only if both columns has null values.\n",
    "test_data.dropna(subset=['title_year', 'movie_title'], how = \"all\", inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing  with error-prone columns\n",
    "\n",
    "- We can apply the same kind of criteria to our __columns.__ \n",
    "- But we just need to use the parameter __axis=1__ in our code. \n",
    "- That means to operate on columns, not rows. \n",
    "\n",
    "> _Do not run the code below if you do not want to delete data - otherwise feel free to experiment!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(5043, 28)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns with that are all NA values (we don't have any of these):\n",
    "test_data = data.copy()\n",
    "\n",
    "test_data.dropna(axis=1, how='all', inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(5043, 9)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all columns with *any* NA values:\n",
    "test_data = data.copy()\n",
    "\n",
    "test_data.dropna(axis=1, how='any', inplace=True)\n",
    "test_data.shape\n",
    "\n",
    "# Note: we can use same threshold and subset params as we did with rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalize data types\n",
    "\n",
    "- Sometimes, especially when we are reading in a CSV with a bunch of numbers, some of the numbers will read in as __strings__ instead of numeric values, or vice versa.\n",
    "\n",
    "- Let's review a couple of ways to fix and normlise our data types.\n",
    "\n",
    "- Please note that we are going to read data from disk again, so the types are converted on data rparsing\n",
    "\n",
    "- If we just run the next line of code it owuld throw an error! Complaining about NaN values. We need to save our previous results into a file and then read the file again. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       178\n1       169\n2       148\n3       164\n4       132\n       ... \n3750    110\n3751     90\n3752     77\n3753     81\n3754     90\nName: duration, Length: 3755, dtype: int64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. save results into the file again\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data.to_csv('data/movie_metadata_cleaned.csv')\n",
    "\n",
    "# 2. read from the file again\n",
    "\n",
    "data = pd.read_csv('data/movie_metadata_cleaned.csv')\n",
    "\n",
    "# Look at how the duration field has been read in (float)\n",
    "data.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0       178\n1       169\n2       148\n3       164\n4       132\n       ... \n3750    110\n3751     90\n3752     77\n3753     81\n3754     90\nName: duration, Length: 3755, dtype: int64"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now force it to be an integer\n",
    "data = pd.read_csv('data/movie_metadata_cleaned.csv', dtype={'duration': int})\n",
    "data.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0         936.0\n1        5000.0\n2         393.0\n3       23000.0\n4         632.0\n         ...   \n3750      133.0\n3751        0.0\n3752       45.0\n3753       20.0\n3754       23.0\nName: actor_2_facebook_likes, Length: 3755, dtype: float64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same with actor_2_facebook_likes field\n",
    "\n",
    "data = pd.read_csv('data/movie_metadata_cleaned.csv')\n",
    "data.actor_2_facebook_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force actor_2_facebook_likes to be a string\n",
    "\n",
    "data = pd.read_csv('data/movie_metadata_cleaned.csv', dtype={'actor_2_facebook_likes': str})\n",
    "data.actor_2_facebook_likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Change casing\n",
    "\n",
    "- Columns with user-provided data are ripe for corruption. \n",
    "- People make typos, leave their caps lock on (or off), and add extra spaces where they shouldn’t.\n",
    "- Let's see how to correct these issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0                                         AVATAR \n1       PIRATES OF THE CARIBBEAN: AT WORLD'S END \n2                                        SPECTRE \n3                          THE DARK KNIGHT RISES \n4                                    JOHN CARTER \n                          ...                    \n3750                                       CLEAN \n3751                                  THE CIRCLE \n3752                                      PRIMER \n3753                                 EL MARIACHI \n3754                           MY DATE WITH DREW \nName: movie_title, Length: 3755, dtype: object"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['movie_title'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0                                         Avatar\n1       Pirates of the Caribbean: At World's End\n2                                        Spectre\n3                          The Dark Knight Rises\n4                                    John Carter\n                          ...                   \n3750                                       Clean\n3751                                  The Circle\n3752                                      Primer\n3753                                 El Mariachi\n3754                           My Date with Drew\nName: movie_title, Length: 3755, dtype: object"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Let's get rid of trailing whitespace\n",
    "data['movie_title'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DID YOU KNOW:  \n",
    "\n",
    "### It is also possible to correct spelling mistakes in your data!\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "- We will not be covering this in our course, but you can read about it in your spare time\n",
    "- It is called __FUZZY MATCHING__ \n",
    "- Fuzzy string matching uses __[Levenshtein Distance] (https://en.wikipedia.org/wiki/Levenshtein_distance)__ to calculate the differences between sequences\n",
    "- note the exclamation sign below\n",
    "    \n",
    "</div>\n",
    "\n",
    "<img src=\"data/images/fuzzy.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rename columns\n",
    "\n",
    "- If your data was generated by a computer program, it probably has some computer-generated column names too. \n",
    "- Those can be hard to read and understand while working\n",
    "- We can rename a column to something more user-friendly\n",
    "- we have already practiced that in earlier pandas tutorial, let's remind ourselves how to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.rename(columns = {'title_year':'release_date', 'movie_facebook_likes':'facebook_likes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Saving Results\n",
    "\n",
    "- When you’re done cleaning your data, you may want to export it back into CSV format for further processing in another program.\n",
    "- Always remember to save your data, otherwise all our efforts would be lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('data/movie_metadata_cleaned.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NON-CODING DEMO SLIDES\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "- There are many advanced techniques on how you can clean, inspect, process data\n",
    "\n",
    "- <b>We won't do any coding</b>, but we will have a high level walk through to review some of them\n",
    "\n",
    "- In the future you can explore these techniques in more detail\n",
    "</div>\n",
    "\n",
    "\n",
    "## Let's review how to identify and see:\n",
    "\n",
    "- ##### Missing Data\n",
    "- ##### Irregular Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Technique 1: Missing Data Heatmap\n",
    "\n",
    "- When there is a smaller number of features, we can visualize the missing data via heatmap.\n",
    "- The chart below demonstrates the missing data patterns of the first 30 features. \n",
    "    - The horizontal axis shows the feature name; \n",
    "    - the vertical axis shows the number of observations/rows; \n",
    "    - the yellow color represents the missing data while the blue color otherwise.\n",
    "    \n",
    "    \n",
    "<img src=\"data/images/missing1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Technique 2: Missing Data Percentage List\n",
    "\n",
    "- When there are many features in the dataset, we can make a list of missing data % for each feature.\n",
    "- The list below shows the percentage of missing values for each of the features.\n",
    "\n",
    "<img src=\"data/images/missing2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Technique 3: Missing Data Histogram\n",
    "\n",
    "- Missing data histogram is also a technique for when we have many features.\n",
    "- To learn more about the missing value patterns among observations, we can visualize it by a histogram.\n",
    "- This histogram helps to identify the missing values situations among the 30,471 observations.\n",
    "\n",
    "<img src=\"data/images/missing3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Irregular data (Outliers)\n",
    "\n",
    "- Outliers are data that is distinctively different from other observations. \n",
    "- They could be real outliers or mistakes.\n",
    "- Depending on whether the feature is numeric or categorical, we can use different techniques to study its distribution to detect outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Technique 1: Histogram/Box Plot\n",
    "\n",
    "- When the feature is numeric, we can use a histogram and box plot to detect outliers.\n",
    "- The data looks highly skewed with the possible existence of outliers.\n",
    "\n",
    "<img src=\"data/images/outlier1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Technique 2: Bar Chart\n",
    "\n",
    "- When the feature is categorical, we can use a bar chart to learn about its categories and distribution.\n",
    "- For example, the feature ecology has a reasonable distribution. \n",
    "- But if there is a category with only one value called “other”, then that would be an outlier.\n",
    "\n",
    "<img src=\"data/images/outlier2.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Unnecessary data\n",
    "\n",
    "- All the data feeding into the model should serve the purpose of the project. \n",
    "- The unnecessary data is when the data doesn’t add value. \n",
    "- We cover two main types of unnecessary data due to different reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Unnecessary type 1: Uninformative / Repetitive\n",
    "\n",
    "- Sometimes one feature is uninformative because it has too many rows being the same value.\n",
    "- We can create a list of features with a high percentage of the same value.\n",
    "- For example, we specify below to show features with over 95% rows being the same value.\n",
    "\n",
    "<img src=\"data/images/unnecessary1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Unnecessary type 2: Duplicates\n",
    "\n",
    "- The duplicate data is when copies of the same observation exist.\n",
    "- There are two main types of duplicate data\n",
    "\n",
    "__1. Duplicates type 1: All Features based__\n",
    "\n",
    "- This duplicate happens when all the features’ values within the observations are the same. \n",
    "\n",
    "__2.Duplicates type 2: Key Features based__\n",
    "\n",
    "- Sometimes it is better to remove duplicate data based on a set of unique identifiers.\n",
    "- For example, the chances of two transactions happening at the same time, with the same square footage, the same price, and the same build year are close to zero.\n",
    "- We can set up a group of critical features as unique identifiers for transactions and we check if there are duplicates based on them.\n",
    "\n",
    "> We will need to identiy and remove those duplicates (if necessary)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
