{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CrRQKB2wkMW"
   },
   "source": [
    "# Pandas is a library that helps you work with data as tables\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"data/images/pandas.png\" alt=\"pandas library\" style=\"width: 400px;\"/> </td>\n",
    "<td> <img src=\"data/images/pandas1.png\" alt=\"pandas library alternative\" style=\"width: 400px;\"/></td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "\n",
    "## Quick recap on 'Library'\n",
    "- A library allows you to reuse code someone else has kindly written for us\n",
    "- The concept of library ecosystem is one of the reasons Python is so popular today\n",
    "- Some libraries are included in Python by default, others can be installed via `pip` and you can also make your own!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1641562675340,
     "user": {
      "displayName": "Polly Moore",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgXW6o21_E1mIFeTJ6lfYpulwNphQU8hizkxAFc=s64",
      "userId": "15644481837663351307"
     },
     "user_tz": 0
    },
    "id": "yvPhcq-VwkMd",
    "outputId": "c4489b6e-124b-4598-bc3f-e00e74ce4809"
   },
   "outputs": [],
   "source": [
    "## [Q1] What will the cell below do?\n",
    "\n",
    "import random\n",
    "random.randint(1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WslaTnJ5wkMg"
   },
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "### `Pandas` is named after __Panel Data__ which is a concept about __multidimensional matricies__. \n",
    "\n",
    "<img src=\"data/images/wes.jpg\" style=\"width: 200px;\"/>\n",
    "\n",
    "Pandas was originally written by [Wes McKinney](https://en.wikipedia.org/wiki/Wes_McKinney) who was working at a hedge fund and needed a tool to better deal with the time-series data he was working with day to day. It's a great story for a few reasons:\n",
    "\n",
    "1. It's a great example of an open source project going far and beyond what the creator anticipated.\n",
    "2. He's admitted that when he started the project he wasn't very good at Python. \n",
    "3. This amazing tool used by thousands of people was made by 'just some guy'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jnfx1IXwkMh"
   },
   "source": [
    "## How to use Pandas\n",
    "\n",
    "\n",
    "ALWAYS REMEMBER: **NO ONE WAS BORN KNOWING ALL OF THIS**\n",
    "\n",
    "Everyone was a beginner once (even Wes McKinney) and help is available. The answer to pretty much every Python / Pandas question WILL be online, getting good at \"Googling\" is arguably the best skill you can have as a programmer.\n",
    "\n",
    "- The [official documentation](https://pandas.pydata.org/pandas-docs/stable/) is great\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzqSuinawkMi"
   },
   "source": [
    "### To start using Pandas you need to import it\n",
    "\n",
    "- The code below is very much convention, you don't need to do the `pd` part - but most end up doing so for ease when typing. \n",
    "- Programmers are lazy, remember that's why we care about 'efficiency' - less actual work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRi42iUtwkMj"
   },
   "outputs": [],
   "source": [
    "import pandas # you can do this and it's totally fine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diiaOCvDwkMk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # most people do this to avoid typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-gFg1tIwkMl"
   },
   "outputs": [],
   "source": [
    "pd. #Press tab to see autocomplete "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfeZIWHiwkMm"
   },
   "source": [
    "# The world runs on Excel\n",
    "\n",
    "- It's on everyones computer\n",
    "- It's not going anywhere\n",
    "- It's in use everywhere from small businesses to Nuclear power plants\n",
    "\n",
    "### - Pandas can make our life easy, because it has lots of fancy features, which allow us to work with Excel spreadsheets and many more!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xiq6tThowkMo"
   },
   "source": [
    "# Opening a Spreadsheet in Pandas is simple...\n",
    "\n",
    "## [Q2] What do you think `pd.DataFrame.head()` does?\n",
    " Let's try it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1641563130797,
     "user": {
      "displayName": "Polly Moore",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgXW6o21_E1mIFeTJ6lfYpulwNphQU8hizkxAFc=s64",
      "userId": "15644481837663351307"
     },
     "user_tz": 0
    },
    "id": "owxAB34-wkMp",
    "outputId": "e863a277-bbe3-41d7-e71c-3f034efa7372"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "excel_df = pd.read_excel('data/movies.xls', sheet_name='1900s')\n",
    "excel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEQOd4BdwkMr"
   },
   "source": [
    "## [Q3] How do you think we could preview the last 10 rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9274ndJwkMs",
    "outputId": "2cf95cfb-f0d0-4e0f-bd18-4d91717c305f"
   },
   "outputs": [],
   "source": [
    "excel_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwV_V_HewkMt"
   },
   "source": [
    "# How to filter columns in Pandas\n",
    "\n",
    "- There are a couple of ways to do this\n",
    "- The simplest way is to pass a list of columns to the DataFrame within square brackets `[]`\n",
    "- This is very similar to what you've seen with `List` objects e.g. `[1,2,3,4]`\n",
    "\n",
    "\n",
    "`data_frame[[col1, col2, col3 ...]]`\n",
    "\n",
    "This looks a little funny but the two sets of square brackets are doing different things.\n",
    "1. The first set (outermost) are saying: 'Please provide me with a sequence of column names'\n",
    "2. The second (innermost) set are simply an explicit set of columns to select\n",
    "\n",
    "Run the cell below to select to see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pW0WL9KbwkMt",
    "outputId": "de516574-6dae-4c83-fe96-348b1d7f26ff"
   },
   "outputs": [],
   "source": [
    "excel_df[['Title', 'Year']].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lE-N2T3YwkMu",
    "outputId": "11c3f4e9-d739-46fd-dab6-bf354f6053c5"
   },
   "outputs": [],
   "source": [
    "# It might help to see that the code below is functionally identical...\n",
    "\n",
    "columns_to_select = ['Title', 'Year']\n",
    "excel_df[columns_to_select].sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t60vXtgfwkMv"
   },
   "source": [
    "## [Q4] Filter the table to just the following columns and show the first 5 rows\n",
    "```python\n",
    "['Title', 'Year', 'Genres', 'Language', 'Country', 'Content Rating', 'Budget', 'IMDB Score']\n",
    "```\n",
    "- Note: You must be explicit, misspelling will give you a `KeyError`\n",
    "- Save the results in the variable `test_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3yG2BLKwkMv"
   },
   "outputs": [],
   "source": [
    "test_df = excel_df[['Title', 'Year', 'Genres', 'Language', 'Country', 'Content Rating', 'Budget', 'IMDB Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdJL6gI9wkMw"
   },
   "source": [
    "# How to filter rows in Pandas\n",
    "\n",
    "- If you run the cell below you will see that the selecting of a single column, not a list of columns, looks different...\n",
    "- This is because one column is actually called a `Series` and you can think about it like a vertical list\n",
    "- When you break it down, a DataFrame is just a group of `Series` columns behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zA53YYI3wkMw",
    "outputId": "51af3416-bfea-4c32-9223-06b983cf1487"
   },
   "outputs": [],
   "source": [
    "test_df['Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86rI5BqZwkMx"
   },
   "source": [
    "- When you do a comparison against a the `Series`, Pandas will compare every item and return `True` or `False` against every row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twL1wUN1wkMx",
    "outputId": "6c9cf604-753e-43e6-a35d-88cb88e0983f"
   },
   "outputs": [],
   "source": [
    "test_df['Year'] == 1920"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8MZWcXawkMx"
   },
   "source": [
    "- When you put this within the square brackets of a DataFrame, Pandas will filter to the rows which were `True`\n",
    "\n",
    "## [Q5] Filter the `test_df` to rows where the IMDB Score is greater than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nkvsm8zrwkMy",
    "outputId": "f6095644-5d9d-4a21-e04a-b229b08d50e2"
   },
   "outputs": [],
   "source": [
    "test_df[test_df['IMDB Score'] > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Tk9UBkEwkMy"
   },
   "source": [
    "## [Q6] Filter the `test_df` to films from the USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFR0dnXKwkMz",
    "outputId": "107d2a79-9070-44f3-9e96-66de62c1572a"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_df[test_df['Country'] == 'USA'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHOxpJaIwkMz"
   },
   "outputs": [],
   "source": [
    "# another cool example \n",
    "\n",
    "# reset test_df first\n",
    "test_df = excel_df[['Title', 'Year', 'Genres', 'Language', 'Country', 'Content Rating', 'Budget', 'IMDB Score']]\n",
    "\n",
    "condition_1 = (test_df['Country'] == 'USA')\n",
    "condition_2 = (test_df['Country'] == 'UK')\n",
    "condition_3 = (test_df['Country'] == 'Germany')\n",
    "\n",
    "test_df= condition_1 | condition_2\n",
    "\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWrNiub4wkM0"
   },
   "source": [
    "## You can use the following operators to combine conditions:\n",
    "- `&` to AND conditions together, e.g. The can was GREEN and CLOSED \n",
    "- `|` to OR conditions together, e.g. The person was from England or France (either is fine)\n",
    "- `~` to NEGATE any condition, e.g. The person was not from London\n",
    "- It's also useful to put conditions in brackets `(`to make sure things working in the right order`)`\n",
    "\n",
    "For example you could filter a `DataFrame` like so:\n",
    "\n",
    "`df[(df['age'] >= 18) & (df['height'] < 200)]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qR-paBwfwkM0",
    "outputId": "620ee44e-4cd3-46c8-88ef-42ce0d8dac2e"
   },
   "outputs": [],
   "source": [
    "# This one is a little harder...\n",
    "## [Q7] Filter the test_df to films which were made in the 1920s\n",
    "\n",
    "\n",
    "test_df[(test_df['Year'] >= 1920) & (test_df['Year'] <= 1929)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6OncZ51wkM1"
   },
   "source": [
    "## Getting a sense of the data you have to work with\n",
    "If you ever want to just get a numeric sense of the data in your `DataFrame` the `describe()` function is built for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnKJSoWlwkM1",
    "outputId": "654ce1cb-0f15-402a-a890-c039fe03bbe4"
   },
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBHjMaLCwkM1"
   },
   "source": [
    "# Let's take a second to recap\n",
    "\n",
    "What you've learnt so far:\n",
    "- Pandas is a library that comes with lots of built-in tools for working with data\n",
    "- It provides several ways of previewing the data you are working with\n",
    "- You can filter columns by passing a sequence of column names\n",
    "- You can filter rows by applying conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkaFafiWwkM2",
    "outputId": "a6945d91-497d-4b6e-e2c8-521831133528",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# If we filter the original data to the following set we can see we are left with 46 rows and 25 columns\n",
    "\n",
    "first_half_century_df = excel_df[excel_df.Year < 1950]\n",
    "first_half_century_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFdU4GvLwkM2"
   },
   "source": [
    "## [Q8] What was the mean budget of movies produced before 1950\n",
    "\n",
    "- With the filtered `first_half_century_df`, work out the mean budget \n",
    "> (Hint: Use the Budget column itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wzlgQOPwkM3",
    "outputId": "ec8903fc-ddf0-4812-9b3f-c779c4f95a63"
   },
   "outputs": [],
   "source": [
    "budget = first_half_century_df['Budget']\n",
    "format(budget.mean(), ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5ehLF8dwkM3"
   },
   "source": [
    "## [Q9] What was the minimum budget of movies produced before 1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SisKnGzNwkM3",
    "outputId": "f906c937-c8d9-4aef-c254-290b981fd937"
   },
   "outputs": [],
   "source": [
    "budget.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI1_XeC4wkM4"
   },
   "source": [
    "## [Q10] What was the maximum budget of movies produced before 1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZPCT4anwkM4",
    "outputId": "a8970410-288b-4798-acca-dc459c36ac9a"
   },
   "outputs": [],
   "source": [
    "budget.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6cu3EUbwkM5"
   },
   "source": [
    "## Let's have a look at how we can write csv files with Pandas!\n",
    "\n",
    "\n",
    "<img src=\"data/images/apple-stock.jpg\" style=\"width: 200px;\"/>\n",
    "\n",
    " - We are going to use a finance API to fetch stock prices for Apple (from internet)\n",
    " - Then we are going to write fetched data to a CSV\n",
    " - Finally, we are going to learn how to read a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um-mv7kOwkM5"
   },
   "source": [
    "## Datareader \n",
    "\n",
    "\n",
    "<img src=\"data/images/datareader.jpg\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "- The Pandas datareader is a sub package that allows one to create a dataframe from various IN-BUILT internet datasources\n",
    "- We can fetch historical stock prices, quotes etc from various world exchanges without specifically going to their urls. \n",
    "\n",
    "Heres is  list of in-built datareaders: https://pandas-datareader.readthedocs.io/en/latest/readers/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-22 00:00:00-04:00</th>\n",
       "      <td>159.300003</td>\n",
       "      <td>162.139999</td>\n",
       "      <td>157.809998</td>\n",
       "      <td>157.830002</td>\n",
       "      <td>75701800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-23 00:00:00-04:00</th>\n",
       "      <td>158.830002</td>\n",
       "      <td>161.550003</td>\n",
       "      <td>157.679993</td>\n",
       "      <td>158.929993</td>\n",
       "      <td>67622100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-24 00:00:00-04:00</th>\n",
       "      <td>158.860001</td>\n",
       "      <td>160.339996</td>\n",
       "      <td>157.850006</td>\n",
       "      <td>160.250000</td>\n",
       "      <td>59196500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-27 00:00:00-04:00</th>\n",
       "      <td>159.940002</td>\n",
       "      <td>160.770004</td>\n",
       "      <td>157.869995</td>\n",
       "      <td>158.279999</td>\n",
       "      <td>52390300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-28 00:00:00-04:00</th>\n",
       "      <td>157.970001</td>\n",
       "      <td>158.490005</td>\n",
       "      <td>155.979996</td>\n",
       "      <td>157.649994</td>\n",
       "      <td>45992200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 00:00:00-04:00</th>\n",
       "      <td>159.369995</td>\n",
       "      <td>161.050003</td>\n",
       "      <td>159.350006</td>\n",
       "      <td>160.770004</td>\n",
       "      <td>51305700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30 00:00:00-04:00</th>\n",
       "      <td>161.529999</td>\n",
       "      <td>162.470001</td>\n",
       "      <td>161.270004</td>\n",
       "      <td>162.360001</td>\n",
       "      <td>49501700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31 00:00:00-04:00</th>\n",
       "      <td>162.440002</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>161.910004</td>\n",
       "      <td>164.899994</td>\n",
       "      <td>68694700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 00:00:00-04:00</th>\n",
       "      <td>164.270004</td>\n",
       "      <td>166.289993</td>\n",
       "      <td>164.220001</td>\n",
       "      <td>166.169998</td>\n",
       "      <td>56976200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04 00:00:00-04:00</th>\n",
       "      <td>166.600006</td>\n",
       "      <td>166.839996</td>\n",
       "      <td>165.110001</td>\n",
       "      <td>165.630005</td>\n",
       "      <td>46278300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05 00:00:00-04:00</th>\n",
       "      <td>164.740005</td>\n",
       "      <td>165.050003</td>\n",
       "      <td>161.800003</td>\n",
       "      <td>163.759995</td>\n",
       "      <td>51511700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06 00:00:00-04:00</th>\n",
       "      <td>162.429993</td>\n",
       "      <td>164.960007</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>164.660004</td>\n",
       "      <td>45390100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-10 00:00:00-04:00</th>\n",
       "      <td>161.419998</td>\n",
       "      <td>162.029999</td>\n",
       "      <td>160.080002</td>\n",
       "      <td>162.029999</td>\n",
       "      <td>47716900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-11 00:00:00-04:00</th>\n",
       "      <td>162.350006</td>\n",
       "      <td>162.360001</td>\n",
       "      <td>160.509995</td>\n",
       "      <td>160.800003</td>\n",
       "      <td>47644200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-12 00:00:00-04:00</th>\n",
       "      <td>161.220001</td>\n",
       "      <td>162.059998</td>\n",
       "      <td>159.779999</td>\n",
       "      <td>160.100006</td>\n",
       "      <td>50133100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13 00:00:00-04:00</th>\n",
       "      <td>161.630005</td>\n",
       "      <td>165.800003</td>\n",
       "      <td>161.419998</td>\n",
       "      <td>165.559998</td>\n",
       "      <td>68445600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-14 00:00:00-04:00</th>\n",
       "      <td>164.589996</td>\n",
       "      <td>166.320007</td>\n",
       "      <td>163.820007</td>\n",
       "      <td>165.210007</td>\n",
       "      <td>49337200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-17 00:00:00-04:00</th>\n",
       "      <td>165.089996</td>\n",
       "      <td>165.389999</td>\n",
       "      <td>164.029999</td>\n",
       "      <td>165.229996</td>\n",
       "      <td>41516200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-18 00:00:00-04:00</th>\n",
       "      <td>166.100006</td>\n",
       "      <td>167.410004</td>\n",
       "      <td>165.649994</td>\n",
       "      <td>166.470001</td>\n",
       "      <td>49923000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-19 00:00:00-04:00</th>\n",
       "      <td>165.800003</td>\n",
       "      <td>168.160004</td>\n",
       "      <td>165.539993</td>\n",
       "      <td>167.630005</td>\n",
       "      <td>47720200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-20 00:00:00-04:00</th>\n",
       "      <td>166.089996</td>\n",
       "      <td>167.869995</td>\n",
       "      <td>165.559998</td>\n",
       "      <td>166.649994</td>\n",
       "      <td>52456400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-21 00:00:00-04:00</th>\n",
       "      <td>165.050003</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>164.490005</td>\n",
       "      <td>165.020004</td>\n",
       "      <td>58311900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close   \n",
       "Date                                                                        \n",
       "2023-03-22 00:00:00-04:00  159.300003  162.139999  157.809998  157.830002  \\\n",
       "2023-03-23 00:00:00-04:00  158.830002  161.550003  157.679993  158.929993   \n",
       "2023-03-24 00:00:00-04:00  158.860001  160.339996  157.850006  160.250000   \n",
       "2023-03-27 00:00:00-04:00  159.940002  160.770004  157.869995  158.279999   \n",
       "2023-03-28 00:00:00-04:00  157.970001  158.490005  155.979996  157.649994   \n",
       "2023-03-29 00:00:00-04:00  159.369995  161.050003  159.350006  160.770004   \n",
       "2023-03-30 00:00:00-04:00  161.529999  162.470001  161.270004  162.360001   \n",
       "2023-03-31 00:00:00-04:00  162.440002  165.000000  161.910004  164.899994   \n",
       "2023-04-03 00:00:00-04:00  164.270004  166.289993  164.220001  166.169998   \n",
       "2023-04-04 00:00:00-04:00  166.600006  166.839996  165.110001  165.630005   \n",
       "2023-04-05 00:00:00-04:00  164.740005  165.050003  161.800003  163.759995   \n",
       "2023-04-06 00:00:00-04:00  162.429993  164.960007  162.000000  164.660004   \n",
       "2023-04-10 00:00:00-04:00  161.419998  162.029999  160.080002  162.029999   \n",
       "2023-04-11 00:00:00-04:00  162.350006  162.360001  160.509995  160.800003   \n",
       "2023-04-12 00:00:00-04:00  161.220001  162.059998  159.779999  160.100006   \n",
       "2023-04-13 00:00:00-04:00  161.630005  165.800003  161.419998  165.559998   \n",
       "2023-04-14 00:00:00-04:00  164.589996  166.320007  163.820007  165.210007   \n",
       "2023-04-17 00:00:00-04:00  165.089996  165.389999  164.029999  165.229996   \n",
       "2023-04-18 00:00:00-04:00  166.100006  167.410004  165.649994  166.470001   \n",
       "2023-04-19 00:00:00-04:00  165.800003  168.160004  165.539993  167.630005   \n",
       "2023-04-20 00:00:00-04:00  166.089996  167.869995  165.559998  166.649994   \n",
       "2023-04-21 00:00:00-04:00  165.050003  166.449997  164.490005  165.020004   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2023-03-22 00:00:00-04:00  75701800        0.0           0.0  \n",
       "2023-03-23 00:00:00-04:00  67622100        0.0           0.0  \n",
       "2023-03-24 00:00:00-04:00  59196500        0.0           0.0  \n",
       "2023-03-27 00:00:00-04:00  52390300        0.0           0.0  \n",
       "2023-03-28 00:00:00-04:00  45992200        0.0           0.0  \n",
       "2023-03-29 00:00:00-04:00  51305700        0.0           0.0  \n",
       "2023-03-30 00:00:00-04:00  49501700        0.0           0.0  \n",
       "2023-03-31 00:00:00-04:00  68694700        0.0           0.0  \n",
       "2023-04-03 00:00:00-04:00  56976200        0.0           0.0  \n",
       "2023-04-04 00:00:00-04:00  46278300        0.0           0.0  \n",
       "2023-04-05 00:00:00-04:00  51511700        0.0           0.0  \n",
       "2023-04-06 00:00:00-04:00  45390100        0.0           0.0  \n",
       "2023-04-10 00:00:00-04:00  47716900        0.0           0.0  \n",
       "2023-04-11 00:00:00-04:00  47644200        0.0           0.0  \n",
       "2023-04-12 00:00:00-04:00  50133100        0.0           0.0  \n",
       "2023-04-13 00:00:00-04:00  68445600        0.0           0.0  \n",
       "2023-04-14 00:00:00-04:00  49337200        0.0           0.0  \n",
       "2023-04-17 00:00:00-04:00  41516200        0.0           0.0  \n",
       "2023-04-18 00:00:00-04:00  49923000        0.0           0.0  \n",
       "2023-04-19 00:00:00-04:00  47720200        0.0           0.0  \n",
       "2023-04-20 00:00:00-04:00  52456400        0.0           0.0  \n",
       "2023-04-21 00:00:00-04:00  58311900        0.0           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "aapl_stock = yf.Ticker(\"AAPL\")\n",
    "# print(aapl_stock.info)\n",
    "aapl = aapl_stock.history(period=\"1mo\")\n",
    "aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3YOi7SKwkM5",
    "outputId": "e4c1f69a-9f2b-4a1e-9cbf-3ade3d61eb4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "\n",
    "\n",
    "# Try this example, BUT Yahoo Finance has known bugs, so it may not work (their end, theif fault), \n",
    "# so we may need to try option 2\n",
    "\n",
    "import datetime \n",
    "aapl = pdr.yahoo.daily.YahooDailyReader('AAPL', \n",
    "                          start=datetime.datetime(2020, 10, 1), \n",
    "                          end=datetime.datetime(2021, 7, 1))\n",
    "print(aapl)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rmkm3xOOwkM6",
    "outputId": "d356169e-a79f-4752-9724-5e7dd725b2e9"
   },
   "outputs": [],
   "source": [
    "# Alternatively we need to use Tiingo datareader. \n",
    "# Please create a free account to get free token here: https://api.tiingo.com/ (click sign up for free account)\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "\n",
    "api_key='88e4c1e8c4d1d2aede66b18385fd08e7dcb14ec7' # <your OWN API token aka key goes here>\n",
    "\n",
    "start=\"2020-1-1\"\n",
    "end=\"2021-7-1\"\n",
    "\n",
    "df = pdr.tiingo.TiingoDailyReader('AAPL', start=start, end=end, api_key=api_key)\n",
    "\n",
    "\n",
    "aapl = df.read()\n",
    "\n",
    "aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aF341GqewkM6",
    "outputId": "73128b39-0fac-4228-fc9d-bd63e4d67c54"
   },
   "outputs": [],
   "source": [
    "# Great! Now let's write the data we got from this FINANCE API to a new CSV file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "aapl.to_csv('data/aapl_historical.csv',  date_format='%Y-%m-%d') # your fle paths and file name\n",
    "\n",
    "# let's read the file that we have just written\n",
    "saved_df = pd.read_csv('data/aapl_historical.csv', header=0, index_col='Date', parse_dates=True)\n",
    "\n",
    "saved_df"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "pandas_session1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
