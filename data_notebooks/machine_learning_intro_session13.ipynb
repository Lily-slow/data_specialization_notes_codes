{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## OBJECTIVES\n",
    "\n",
    "- We want to get a taste of data manipulation and a little bit of machine learning using python.\n",
    "- This will be just the tip of the iceberg, but a crucial step that will let us practice our skills. \n",
    "- Let's do a very simple example, but ensure that we understand every step along the way\n",
    "\n",
    "<img src=\"data/images/ml.jpg\" style=\"width:700px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## OVERVIEW\n",
    "\n",
    "<img src=\"data/images/adults.png\" style=\"width:700px;\"/>\n",
    "\n",
    "- We are going to use a very popular dataset borrowed from one of the open-source Machine Learning Repositories\n",
    "- Let's say this dataset is called 'Adult' and it contains information about different adults and their profiles. \n",
    "- There are two files: one is used to 'train' a machine (build  a model) and the other one is used for testing. \n",
    "- In this dataset the dependent variable is 'target' ( i.e. we focus on the column called 'target')\n",
    "- This example is a binary classification problem. \n",
    "- __Objective:__ _teach a machine to predict if the salary of a given person is less than or more than 50K_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#loading data\n",
    "\n",
    "train  = pd.read_csv(\"data/ml1_train.csv\")\n",
    "test = pd.read_csv(\"data/ml1_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#let's review our main dataset\n",
    "train.info()\n",
    "\n",
    "# RESULT: the train data has 32561 rows and 15 columns. \n",
    "# Out of these 15 columns, 6 have integers classes and the rest have object (or character) classes. \n",
    "# *we can do a similar check for test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# alternative way of checking dataset columns\n",
    "\n",
    "print (f\"The train data has {train.shape[0]} rows and {train.shape[1]} columns\")\n",
    "print (f\"The test data has {test.shape[0]} rows and {test.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# see what the data looks like\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# check if we have missing values in our data\n",
    "\n",
    "na_train = train.shape[0] - train.dropna().shape[0]\n",
    "print (f\"{na_train} rows have missing values in the train data\")\n",
    "\n",
    "na_test = test.shape[0] - test.dropna().shape[0]\n",
    "print (f\"{na_test} rows have missing values in the test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's check which columns have missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's check our character columns - how many unique values does each column hold\n",
    "\n",
    "categories = train.select_dtypes(include=['object'])\n",
    "categories.apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Dealing with missing values\n",
    "\n",
    " - we identified that we had three columns where some values were missing\n",
    " - these columns affect our records, but we don't want to scrap or lose them completely!\n",
    " - Let's impute these missing values with respective modes\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.workclass.value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.occupation.value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['native.country'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# replacing NULL values with most suitable values \n",
    "# (replacing based on existing data -  check your .csv files to understand where these come from )\n",
    "\n",
    "#Workclass\n",
    "train.workclass = train.workclass.str.strip()\n",
    "train.workclass.fillna('Private',inplace=True)\n",
    "\n",
    "\n",
    "#Occupation\n",
    "train.occupation = train.occupation.str.strip()\n",
    "train.occupation.fillna('Prof-specialty',inplace=True)\n",
    "\n",
    "\n",
    "#Native Country\n",
    "train['native.country'] = train['native.country'].str.strip()\n",
    "train['native.country'].fillna('United-States',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Check no missing values are left in the dataset\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's check the 'target' variable (values in the 'target' column) to investigate if this data is imbalanced or not.\n",
    "\n",
    "# check proportions % of target variable (there are only 2 unique values, \n",
    "# so we should get a % split of these values in our dataset)\n",
    "train.target.value_counts()/train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>75% of the data set belongs to less than 50K class. This means that even if we take a rough guess of target prediction as less than 50K, we'll get 75% accuracy.</b>\n",
    "Let's create a cross tab of the target variable with education. With this, we'll try to understand the influence of education on the target variable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Multiplying by 100 to make the percentages easier to read\n",
    "pd.crosstab(train.education, train.target,margins=True)/train.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### FINDINGS: \n",
    "\n",
    "__out of 75% people with <=50K salary:__ \n",
    "\n",
    "- 27% people are high school graduates, which is correct as people with lower levels of education are expected to earn less. \n",
    "\n",
    "__out of 25% people with >=50K salary:__ \n",
    "\n",
    "- 6% are bachelors and 5% are high-school grads. ==> _this pattern seems to be a matter of concern! We have to consider more variables before coming to a conclusion._\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SCIKIT\n",
    "\n",
    "- Let's try to utilise the mighty SciKit library for the next step. \n",
    "- https://scikit-learn.org/stable/\n",
    "\n",
    "- __IMPORTANT: Scikit accepts data in numeric format! It means that we need to convert the character variables into numeric.__  \n",
    "\n",
    "\n",
    "- To do our conversion, we will use the _labelencoder_ function.\n",
    "\n",
    "- __IMPORTANT: In label encoding, each unique value of a variable gets assigned a number.__ Example: a variable fruit has four values: 'apple', 'banana', 'kiwi', 'melon'. Label encoding this variable will return output as: apple = 2 banana = 0 kiwi = 1 melon = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# let's encode all object type variables\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "for x in train.columns:\n",
    "    if train[x].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder() # encoding\n",
    "        lbl.fit(list(train[x].values)) # fitting the model\n",
    "        train[x] = lbl.transform(list(train[x].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# examine the dataset again to see how our encoding changes have been applied\n",
    "\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CLOSING REMARKS\n",
    "\n",
    "1. It was our first step towards familiarising ourselves with the world of Machine Learning.\n",
    "1. Hopeully you found it interesting!\n",
    "1. Next time we will cover more individual examples of ML processing and SciKit library. \n",
    "1. Remember, it takes months and sometimes years to build, fit and validate solid ML models. We won't be able to complete the full cycle, but we will focus on key concepts, preprocessing and visualisation ¯\\_(ツ)_/¯\n",
    "\n",
    "<img src=\"data/images/remarks.jpeg\" style=\"width:200px;\" />"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
